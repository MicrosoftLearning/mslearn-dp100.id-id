{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Membuat Alur\n",
        "\n",
        "Anda dapat melakukan berbagai langkah yang diperlukan untuk menyerap data, melatih model, dan mendaftarkan model satu per satu dengan menggunakan SDK Azure Machine Learning untuk menjalankan eksperimen berbasis skrip. Tetapi, dalam lingkungan perusahaan, merupakan hal yang umum untuk menyertakan urutan langkah-langkah terpisah yang diperlukan untuk membangun solusi pembelajaran mesin ke dalam *alur* yang dapat dijalankan pada satu atau beberapa target komputasi; baik sesuai permintaan pengguna, dari proses pembuatan otomatis, atau sesuai jadwal.\n",
        "\n",
        "Dalam buku catatan ini, Anda akan menyatukan semua elemen ini untuk membuat alur sederhana yang memproses data sebelumnya, lalu melatih dan mendaftarkan model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Menghubungkan ke ruang kerja Anda\n",
        "\n",
        "Untuk memulai, hubungkan ke ruang kerja Anda.\n",
        "\n",
        "> **Catatan**: Jika Anda belum membuat sesi yang terautentikasi dengan langganan Azure, Anda akan diminta untuk mengautentikasi dengan mengklik tautan, memasukkan kode autentikasi, dan masuk ke Azure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367166880
        }
      },
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mempersiapkan data\n",
        "\n",
        "Di alur, Anda akan menggunakan himpunan data yang berisi detail pasien diabetes. Jalankan sel di bawah ini untuk membuat himpunan data ini (jika Anda membuat himpunan data sebelumnya, kode akan menemukan versi yang ada)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367169674
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    Dataset.File.upload_directory(src_dir='data',\n",
        "                              target=DataPath(default_ds, 'diabetes-data/')\n",
        "                              )\n",
        "\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # Register the tabular dataset\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Membuat skrip untuk langkah-langkah alur\n",
        "\n",
        "Alur terdiri dari satu atau lebih *langkah*, yang dapat berupa skrip Python, atau langkah khusus seperti langkah transfer data yang menyalin data dari satu lokasi ke lokasi lain. Setiap langkah dapat berjalan dalam konteks komputasi langkah tersendiri. Dalam latihan ini, Anda akan membuat alur sederhana yang berisi dua langkah skrip Python: satu untuk melakukan pra-proses beberapa data pelatihan, dan satu lagi untuk menggunakan data yang telah diproses sebelumnya untuk melatih dan mendaftarkan model.\n",
        "\n",
        "Pertama, mari kita buat folder untuk file skrip yang akan kita gunakan dalam langkah-langkah alur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367172572
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Create a folder for the pipeline step files\n",
        "experiment_folder = 'diabetes_pipeline'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(experiment_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sekarang mari kita buat skrip pertama, yang akan membaca data dari himpunan data diabetes dan menerapkan beberapa pra-pemrosesan sederhana untuk menghapus setiap baris dengan data yang hilang dan menormalkan fitur numerik sehingga berada pada skala yang sama.\n",
        "\n",
        "Skrip menyertakan argumen bernama **--prepped-data**, yang merujuk ke folder tempat data yang dihasilkan akan disimpan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/prep_diabetes.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from azureml.core import Run\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
        "args = parser.parse_args()\n",
        "save_folder = args.prepped_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the data (passed as an input dataset)\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "# Log raw row count\n",
        "row_count = (len(diabetes))\n",
        "run.log('raw_rows', row_count)\n",
        "\n",
        "# remove nulls\n",
        "diabetes = diabetes.dropna()\n",
        "\n",
        "# Normalize the numeric columns\n",
        "scaler = MinMaxScaler()\n",
        "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
        "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\n",
        "\n",
        "# Log processed rows\n",
        "row_count = (len(diabetes))\n",
        "run.log('processed_rows', row_count)\n",
        "\n",
        "# Save the prepped data\n",
        "print(\"Saving Data...\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "save_path = os.path.join(save_folder,'data.csv')\n",
        "diabetes.to_csv(save_path, index=False, header=True)\n",
        "\n",
        "# End the run\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sekarang Anda dapat membuat skrip untuk langkah kedua, yang akan melatih model. Skrip menyertakan argumen bernama **--training-data**, yang merujuk ke lokasi penyimpanan data yang disimpan oleh langkah sebelumnya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/train_diabetes.py\n",
        "# Import libraries\n",
        "from azureml.core import Run, Model\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\n",
        "args = parser.parse_args()\n",
        "training_data = args.training_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the prepared data file in the training folder\n",
        "print(\"Loading Data...\")\n",
        "file_path = os.path.join(training_data,'data.csv')\n",
        "diabetes = pd.read_csv(file_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train adecision tree model\n",
        "print('Training a decision tree model...')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "# Plot the diagonal 50% line\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "# Plot the FPR and TPR achieved by our model\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "run.log_image(name = \"ROC\", plot = fig)\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model in the outputs folder\n",
        "print(\"Saving model...\")\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "model_file = os.path.join('outputs', 'diabetes_model.pkl')\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "\n",
        "# Register the model\n",
        "print('Registering model...')\n",
        "Model.register(workspace=run.experiment.workspace,\n",
        "               model_path = model_file,\n",
        "               model_name = 'diabetes_model',\n",
        "               tags={'Training context':'Pipeline'},\n",
        "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\n",
        "\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mempersiapkan lingkungan komputasi untuk langkah-langkah alur\n",
        "\n",
        "Dalam latihan ini, Anda akan menggunakan komputasi yang sama untuk kedua langkah, tetapi penting untuk menyadari bahwa setiap langkah dijalankan secara independen; sehingga Anda dapat menentukan konteks komputasi yang berbeda untuk setiap langkah jika sesuai.\n",
        "\n",
        "Pertama, dapatkan target komputasi yang Anda buat di lab sebelumnya (jika tidak ada, lab akan dibuat).\n",
        "\n",
        "> **Penting**: Ubah *your-compute-cluster* menjadi nama kluster komputasi Anda dalam kode di bawah ini sebelum menjalankannya! Nama kluster harus berupa nama unik global dengan panjang antara 2 hingga 16 karakter. Karakter yang valid adalah huruf, angka, dan - karakter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367181165
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"your-compute-cluster\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Catatan**: Instans dan kluster komputasi didasarkan pada gambar mesin virtual Azure standar. Untuk latihan ini, gambar *Standard_DS11_v2* direkomendasikan untuk mencapai keseimbangan optimal antara biaya dan performa. Jika langganan Anda memiliki kuota yang tidak menyertakan gambar ini, pilih gambar alternatif; tetapi perlu diingat bahwa gambar yang lebih besar mungkin memerlukan biaya lebih tinggi dan gambar yang lebih kecil mungkin tidak cukup untuk menyelesaikan tugas. Atau, minta administrator Azure Anda untuk memperbesar kuota Anda.\n",
        "\n",
        "Komputasi akan membutuhkan lingkungan Python dengan dependensi paket yang diperlukan diinstal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\n",
        "name: experiment_env\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- ipykernel\n",
        "- matplotlib\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - pyarrow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sekarang setelah Anda memiliki file konfigurasi Conda, Anda dapat membuat lingkungan dan menggunakannya dalam konfigurasi eksekusi untuk alur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367186836
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
        "\n",
        "# Register the environment \n",
        "experiment_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'experiment_env')\n",
        "\n",
        "# Create a new runconfig object for the pipeline\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# Use the compute you created above. \n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# Assign the environment to the run configuration\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print (\"Run configuration created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Membuat dan menjalankan alur\n",
        "\n",
        "Sekarang Anda siap untuk membuat dan menjalankan alur.\n",
        "\n",
        "Pertama, Anda perlu menentukan langkah-langkah untuk alur, dan referensi data apa pun yang perlu diteruskan di antara keduanya. Dalam kasus ini, langkah pertama harus menulis data yang telah disiapkan ke folder yang dapat dibaca oleh langkah kedua. Karena langkah-langkah tersebut akan dijalankan pada komputasi jarak jauh (dan kenyataannya, masing-masing dapat dijalankan pada komputasi yang berbeda), jalur folder harus diteruskan sebagai referensi data ke lokasi di penyimpanan data dalam ruang kerja. Objek **OutputFileDatasetConfig** adalah jenis referensi data khusus yang digunakan untuk lokasi penyimpanan sementara yang dapat diteruskan di antara langkah-langkah alur, jadi Anda akan membuatnya dan menggunakan at sebagai output untuk langkah pertama dan input untuk tahap kedua. Perhatikan bahwa Anda harus meneruskannya sebagai argumen skrip sehingga kode Anda dapat mengakses lokasi penyimpanan data yang dirujuk oleh referensi data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367189787
        }
      },
      "outputs": [],
      "source": [
        "from azureml.data import OutputFileDatasetConfig\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
        "\n",
        "# Step 1, Run the data prep script\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"prep_diabetes.py\",\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n",
        "                                             '--prepped-data', prepped_data],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "# Step 2, run the training script\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"train_diabetes.py\",\n",
        "                                arguments = ['--training-data', prepped_data.as_input()],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "print(\"Pipeline steps defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OK, Anda sudah siap membangun alur dari langkah-langkah yang telah Anda tetapkan dan menjalankannya sebagai eksperimen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367288774
        },
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Construct the pipeline\n",
        "pipeline_steps = [prep_step, train_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print(\"Pipeline submitted for execution.\")\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Representasi grafis dari eksperimen alur akan ditampilkan di widget saat dijalankan. Perhatikan indikator kernel di kanan atas halaman, ketika indikator berubah dari **&#9899;** menjadi **&#9711;**, kode telah selesai dijalankan. Anda juga dapat memantau eksekusi alur di halaman **Eksperimen** di [Studio Azure Machine Learning](https://ml.azure.com).\n",
        "\n",
        "Saat alur selesai, Anda dapat memeriksa metrik yang dicatat oleh eksekusi turunan alur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367294378
        }
      },
      "outputs": [],
      "source": [
        "for run in pipeline_run.get_children():\n",
        "    print(run.name, ':')\n",
        "    metrics = run.get_metrics()\n",
        "    for metric_name in metrics:\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dengan asumsi alur berhasil, model baru akan didaftarkan dengan tag *Konteks pelatihan* yang menunjukkan bahwa model tersebut dilatih dalam alur. Jalankan kode berikut untuk memverifikasi hal ini."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367297400
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Menerbitkan alur\n",
        "\n",
        "Setelah membuat dan menguji alur, Anda dapat menerbitkan alur sebagai layanan REST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367300325
        }
      },
      "outputs": [],
      "source": [
        "# Publish the pipeline from the run\n",
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name=\"diabetes-training-pipeline\", description=\"Trains diabetes model\", version=\"1.0\")\n",
        "\n",
        "published_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perhatikan bahwa alur yang diterbitkan memiliki titik akhir, yang dapat Anda lihat di halaman **Titik akhir** (pada tab **Titik Akhir Alur**) di [Studio Azure Machine Learning](https://ml.azure.com). Anda juga dapat menemukan URI alur sebagai properti dari objek alur yang diterbitkan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367303243
        }
      },
      "outputs": [],
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Memanggil titik akhir alur\n",
        "\n",
        "Untuk menggunakan titik akhir, aplikasi klien perlu melakukan panggilan REST melalui HTTP. Permintaan ini harus diautentikasi, sehingga header otorisasi diperlukan. Aplikasi yang sebenarnya akan memerlukan perwakilan layanan yang dapat digunakan untuk diautentikasi, tetapi untuk mengujinya, kita akan menggunakan header otorisasi dari koneksi Anda saat ini ke ruang kerja Azure Anda, yang dapat Anda peroleh menggunakan kode berikut:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367306323
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()\n",
        "print(\"Authentication header ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sekarang kita siap untuk memanggil antarmuka REST. Alur berjalan secara asinkron, jadi kita akan mendapatkan pengidentifikasi kembali, yang dapat kita gunakan untuk melacak eksperimen alur saat dijalankan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367309225
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "experiment_name = 'mslearn-diabetes-pipeline'\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": experiment_name})\n",
        "run_id = response.json()[\"Id\"]\n",
        "run_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Karena Anda memiliki ID eksekusi, Anda dapat menggunakannya untuk menunggu eksekusi selesai.\n",
        "\n",
        "> **Catatan**: Alur akan selesai dengan cepat, karena setiap langkah dikonfigurasi untuk memungkinkan penggunaan kembali output. Hal ini dilakukan terutama untuk kenyamanan dan untuk menghemat waktu dalam kursus ini. Pada kenyataannya, Anda mungkin ingin langkah pertama dijalankan setiap kali data berubah, dan memicu langkah-langkah berikutnya hanya jika output dari langkah pertama berubah."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367316814
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Menjadwalkan Alur\n",
        "\n",
        "Misalkan klinik untuk pasien diabetes mengumpulkan data baru setiap minggu, dan menambahkannya ke himpunan data. Anda dapat menjalankan alur setiap minggu untuk melatih ulang model dengan data baru."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367324073
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
        "\n",
        "# Submit the Pipeline every Monday at 00:00 UTC\n",
        "recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Monday\"], time_of_day=\"00:00\")\n",
        "weekly_schedule = Schedule.create(ws, name=\"weekly-diabetes-training\", \n",
        "                                  description=\"Based on time\",\n",
        "                                  pipeline_id=published_pipeline.id, \n",
        "                                  experiment_name='mslearn-diabetes-pipeline', \n",
        "                                  recurrence=recurrence)\n",
        "print('Pipeline scheduled.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Anda dapat mengambil jadwal yang ditentukan di ruang kerja seperti ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367327077
        }
      },
      "outputs": [],
      "source": [
        "schedules = Schedule.list(ws)\n",
        "schedules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Anda dapat memeriksa eksekusi terbaru seperti ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367330036
        }
      },
      "outputs": [],
      "source": [
        "pipeline_experiment = ws.experiments.get('mslearn-diabetes-pipeline')\n",
        "latest_run = list(pipeline_experiment.get_runs())[0]\n",
        "\n",
        "latest_run.get_details()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ini adalah contoh sederhana, yang dirancang untuk menunjukkan prinsip. Pada kenyataannya, Anda dapat membangun logika yang lebih canggih ke dalam langkah-langkah alur - misalnya, mengevaluasi model terhadap beberapa data pengujian untuk menghitung metrik performa seperti AUC atau akurasi, membandingkan metrik dengan versi model yang terdaftar sebelumnya, dan hanya mendaftarkan model baru jika performa model lebih baik.\n",
        "\n",
        "Anda dapat menggunakan [ekstensi Azure Machine Learning untuk Azure DevOps](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml) untuk menggabungkan alur Azure Machine Learning dengan alur Azure DevOps (ya, *memang* membingungkan bahwa keduanya memiliki nama yang sama!) dan mengintegrasikan pelatihan ulang model ke dalam proses *integrasi berkelanjutan/penyebaran berkelanjutan (CI/CD)*. Misalnya, Anda dapat menggunakan alur *pembangunan* Azure DevOps untuk memicu alur Azure Machine Learning yang melatih dan mendaftarkan model, dan ketika model didaftarkan, model dapat memicu alur *rilis* Azure Devops yang menyebarkan model sebagai layanan web, bersama dengan aplikasi atau layanan yang menggunakan model."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
